5. Задача линейной регрессии - найти функцию прямой такого количества переменных, сколько независимых признаков; 
   значением данной функции будет предсказываемое значение. При логистической регрессии мы ищем такую прямую (плоскость и тд), 
   которая поделит наши данные на 2 категории, как правило результатом будет 0 или 1.
6. Градиентный спуск - это метод поиска минимума функции, при котором мы движемся по вектору наибольшего спуска некоторыми шагами, 
   в каждой итерации мы вычисляем шаг по всем переменным функции (то есть по каждой координате). Если переменных много, то такой подход 
   может быть очень ресурсоемким, тогда применяется стохастический градиентный спуск. При этом методе пересчет следующей точки в одной 
   итерации происходит не по всем координатам, а выборочно по некоторым. В итоге итераций понадобится больше, но каждая итерация менее ресурсоемка. 
   При таком спуске точка "гуляет" и приближается к минимуму медленнее и кривыми путями.
7. Уровень, тренд и сезонность.   
